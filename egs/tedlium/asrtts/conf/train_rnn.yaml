# network architecture
# encoder related
etype: vggblstm     # encoder architecture type
elayers: 3
eunits: 512
eprojs: 512
subsample: "1_2_2_1_1" # skip every n frame from input to nth layers
# decoder related
dlayers: 1
dunits: 512
# attention related
atype: location
adim: 512
aconv-chans: 10
aconv-filts: 100

# hybrid CTC/attention
mtlalpha: 0
#model-module: "espnet.nets.pytorch_backend.e2e_asrtts:E2E"

# minibatch related
# batch-count: "seq"
batch-size: 16
maxlen-in: 800  # if input length  > maxlen_in, batchsize is automatically reduced
maxlen-out: 150 # if output length > maxlen_out, batchsize is automatically reduced

# other config
dropout-rate: 0.2

# optimization related
sortagrad: 0 # Feed samples from shortest to longest ; -1: enabled for all epochs, 0: disabled, other: enabled for 'other' epochs
opt: adadelta
#eps: 1e-06
epochs: 30
patience: 0

# scheduled sampling option
sampling-probability: 0.0
